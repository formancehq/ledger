name: Benchmark comparison
on:
  workflow_dispatch:
    inputs:
      bench:
        description: 'Benchmarks to run'
        required: false
        default: '.'
      parallelism:
        description: 'Number of parallel benchmarks to run'
        required: false
        default: 5
      duration:
        description: 'Duration of each benchmark'
        required: false
        default: '10s'
      count:
        description: 'Number of times to run each benchmark '
        required: false
        default: 1
  pull_request:
    types: [ assigned, opened, synchronize, reopened, labeled ]

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number }}
  cancel-in-progress: true

jobs:
  BenchmarkCompare:
    runs-on: "github-001"
    if: contains(github.event.pull_request.labels.*.name, 'benchmarks')
    steps:
      - uses: 'actions/checkout@v4'
        with:
          fetch-depth: 0
      - uses: extractions/setup-just@v2
      - run: >
          just
          --justfile ./test/performance/justfile
          --working-directory ./test/performance 
          compare ${{ inputs.bench }} ${{ inputs.parallelism }} ${{ inputs.duration }} ${{ inputs.count }}
      - run: >
          just 
          --justfile ./test/performance/justfile 
          --working-directory ./test/performance 
          graphs
      - uses: actions/upload-artifact@v4
        with:
          name: graphs
          path: test/performance/report